{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on Nov 4, 2010\n",
    "Chapter 5 source file for Machine Learing in Action\n",
    "@author: Peter\n",
    "'''\n",
    "from numpy import *\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    # 初始化数据和标签列表\n",
    "    dataMat = []; labelMat = []\n",
    "    \n",
    "    # 打开指定文件，返回文件对象\n",
    "    fr = open(fileName)\n",
    "    \n",
    "    # 对文件中的每一行进行迭代\n",
    "    for line in fr.readlines():\n",
    "        # 剔除字符串首尾的空格并按照 '\\t' 分割字符串，存入列表\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        \n",
    "        # 将前两个元素转换为浮点数并添加到数据列表中\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])\n",
    "        \n",
    "        # 将第三个元素转换为浮点数并添加到标签列表中\n",
    "        labelMat.append(float(lineArr[2]))\n",
    "        \n",
    "    # 返回数据和标签列表\n",
    "    return dataMat, labelMat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectJrand(i, m):\n",
    "    \"\"\"\n",
    "    随机选择一个不等于i的整数j，其中0<=j<=m-1\n",
    "    \n",
    "    Args:\n",
    "    i: int, 当前的i值\n",
    "    m: int, 选择j时的上界\n",
    "    \n",
    "    Returns:\n",
    "    j: int, 随机选择的不等于i的整数\n",
    "    \"\"\"\n",
    "    j = i  # 我们想要选择一个不等于i的任何j\n",
    "    \n",
    "    # 当j等于i时，随机选择一个0到m-1之间的整数j\n",
    "    while (j == i):\n",
    "        j = int(random.uniform(0, m))\n",
    "    \n",
    "    # 返回随机选择的不等于i的整数j\n",
    "    return j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipAlpha(aj, H, L):\n",
    "    \"\"\"\n",
    "    将alpha[j]调整到L和H之间的范围内\n",
    "    \n",
    "    Args:\n",
    "    aj: float, 要调整的alpha[j]值\n",
    "    H: float, alpha[j]的上界\n",
    "    L: float, alpha[j]的下界\n",
    "    \n",
    "    Returns:\n",
    "    aj: float, 调整后的alpha[j]值\n",
    "    \"\"\"\n",
    "    # 如果alpha[j]大于上界H，则将其设置为上界H\n",
    "    if aj > H:\n",
    "        aj = H\n",
    "    \n",
    "    # 如果alpha[j]小于下界L，则将其设置为下界L\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    \n",
    "    # 返回调整后的alpha[j]值\n",
    "    return aj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoSimple(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    dataMatrix = mat(dataMatIn)  # 将特征数据转换为矩阵\n",
    "    labelMat = mat(classLabels).transpose()  # 将标签数据转换为矩阵并进行转置\n",
    "    b = 0  # 初始化偏置值为0\n",
    "    m,n = shape(dataMatrix)  # 获取特征矩阵的大小，m：样本数，n：属性个数\n",
    "    alphas = mat(zeros((m,1)))  # 初始化拉格朗日乘子向量alpha为全0的列向量\n",
    "    iter = 0  # 初始化迭代次数为0\n",
    "    while (iter < maxIter):  # 迭代开始\n",
    "        alphaPairsChanged = 0  # 每一轮迭代前重置alpha对的改变次数为0\n",
    "        for i in range(m):  # 遍历每一个样本\n",
    "            fXi = float(multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[i,:].T)) + b  # 计算当前样本的预测值f(x_i)\n",
    "            Ei = fXi - float(labelMat[i])  # 计算误差Ei\n",
    "            if ((labelMat[i]*Ei < -toler) and (alphas[i] < C)) or ((labelMat[i]*Ei > toler) and (alphas[i] > 0)):  # 检查是否违反KKT条件\n",
    "                j = selectJrand(i,m)  # 随机选择另一个样本j\n",
    "                fXj = float(multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[j,:].T)) + b  # 计算样本j的预测值f(x_j)\n",
    "                Ej = fXj - float(labelMat[j])  # 计算误差Ej\n",
    "                alphaIold = alphas[i].copy()  # 备份alpha_i旧值\n",
    "                alphaJold = alphas[j].copy()  # 备份alpha_j旧值\n",
    "                if (labelMat[i] != labelMat[j]):  # 判断两个样本标签是否相同\n",
    "                    L = max(0, alphas[j] - alphas[i])  # 计算L和H的值\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                if L==H: print(\"L==H\"); continue  # 如果L和H相等，则退出当前循环，继续下一次循环\n",
    "                eta = 2.0 * dataMatrix[i,:]*dataMatrix[j,:].T - dataMatrix[i,:]*dataMatrix[i,:].T - dataMatrix[j,:]*dataMatrix[j,:].T  # 计算eta的值\n",
    "                if eta >= 0: print(\"eta>=0\"); continue  # 如果eta大于等于0，则退出当前循环，继续下一次循环\n",
    "                alphas[j] -= labelMat[j]*(Ei - Ej)/eta  # 更新alpha_j的值\n",
    "                alphas[j] = clipAlpha(alphas[j],H,L)  # 调整alpha_j的值在[L, H]区间范围内\n",
    "                if (abs(alphas[j] - alphaJold) < 0.00001): print(\"j not moving enough\"); continue  # 如果alpha_j的变化量太小，则退出当前循环，继续下一次循环\n",
    "                alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j])  # 更新alpha_i的值\n",
    "                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T  # 计算b1和b2的值\n",
    "                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                if (0 < alphas[i]) and (C > alphas[i]): b = b1  # 更新偏置值b\n",
    "                elif (0 < alphas[j]) and (C > alphas[j]): b = b2\n",
    "                else: b = (b1 + b2)/2.0\n",
    "                alphaPairsChanged += 1  # alpha对的改变次数加1\n",
    "                print(\"iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged))  # 打印当前迭代次数、样本编号和alpha对的改变次数\n",
    "        if (alphaPairsChanged == 0): iter += 1  # 如果alpha对的改变次数为0，则迭代次数加1\n",
    "        else: iter = 0\n",
    "        print(\"iteration number: %d\" % iter)  # 打印当前迭代次数\n",
    "    return b,alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernelTrans(X, A, kTup):\n",
    "    \"\"\"\n",
    "    计算核函数或将数据转换到高维空间\n",
    "    \n",
    "    Args:\n",
    "    X: matrix, 输入的特征矩阵\n",
    "    A: matrix, 用于计算核函数的向量\n",
    "    kTup: tuple, 核函数的类型及相关参数\n",
    "    \n",
    "    Returns:\n",
    "    K: matrix, 计算得到的核矩阵\n",
    "    \"\"\"\n",
    "    m, n = shape(X)  # 获取特征矩阵的维度，m为样本数，n为属性个数\n",
    "    K = mat(zeros((m, 1)))  # 初始化核矩阵为0\n",
    "    \n",
    "    if kTup[0] == 'lin':\n",
    "        K = X * A.T  # 线性核函数\n",
    "    elif kTup[0] == 'rbf':\n",
    "        for j in range(m):\n",
    "            deltaRow = X[j, :] - A\n",
    "            K[j] = deltaRow * deltaRow.T\n",
    "        K = exp(K / (-1 * kTup[1] ** 2))  # 在NumPy中除法是逐元素进行的，而不是矩阵运算（类似于Matlab）\n",
    "    else:\n",
    "        raise NameError('Houston We Have a Problem -- That Kernel is not recognized')  # 未识别的核函数类型\n",
    "    \n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optStruct:\n",
    "    def __init__(self, dataMatIn, classLabels, C, toler, kTup):\n",
    "        \"\"\"\n",
    "        初始化优化结构体\n",
    "        \n",
    "        Args:\n",
    "        dataMatIn: matrix, 输入的特征矩阵\n",
    "        classLabels: matrix, 输入的类别标签\n",
    "        C: float, 松弛变量\n",
    "        toler: float, 容错率\n",
    "        kTup: tuple, 核函数的类型及相关参数\n",
    "        \"\"\"\n",
    "        self.X = dataMatIn  # 输入的特征矩阵\n",
    "        self.labelMat = classLabels  # 输入的类别标签\n",
    "        self.C = C  # 松弛变量\n",
    "        self.tol = toler  # 容错率\n",
    "        self.m = shape(dataMatIn)[0]  # 样本数\n",
    "        self.alphas = mat(zeros((self.m, 1)))  # 拉格朗日乘子向量\n",
    "        self.b = 0  # 截距\n",
    "        self.eCache = mat(zeros((self.m, 2)))  # 误差缓存，第一列为有效标志位\n",
    "        self.K = mat(zeros((self.m, self.m)))  # 核矩阵\n",
    "        \n",
    "        # 计算核矩阵\n",
    "        for i in range(self.m):\n",
    "            self.K[:, i] = kernelTrans(self.X, self.X[i, :], kTup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEk(oS, k):\n",
    "    \"\"\"\n",
    "    计算样本k的预测误差\n",
    "    \n",
    "    Args:\n",
    "    oS: optStruct, 优化结构体\n",
    "    k: int, 样本的索引\n",
    "    \n",
    "    Returns:\n",
    "    Ek: float, 样本k的预测误差\n",
    "    \"\"\"\n",
    "    fXk = float(multiply(oS.alphas, oS.labelMat).T * oS.K[:, k] + oS.b)  # 样本k的预测结果\n",
    "    Ek = fXk - float(oS.labelMat[k])  # 样本k的预测误差\n",
    "    return Ek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectJ(i, oS, Ei):\n",
    "    \"\"\"\n",
    "    选择第二个变量alpha_j并计算其预测误差Ej\n",
    "    \n",
    "    Args:\n",
    "    i: int, 第一个变量alpha_i的索引\n",
    "    oS: optStruct, 优化结构体\n",
    "    Ei: float, 第一个变量alpha_i的预测误差\n",
    "    \n",
    "    Returns:\n",
    "    j: int, 第二个变量alpha_j的索引\n",
    "    Ej: float, 第二个变量alpha_j的预测误差\n",
    "    \"\"\"\n",
    "    maxK = -1  # 保存选择的变量alpha_j的索引\n",
    "    maxDeltaE = 0  # 保存选择的变量alpha_j的预测误差与alpha_i预测误差之差的绝对值\n",
    "    Ej = 0  # 保存选择的变量alpha_j的预测误差\n",
    "    oS.eCache[i] = [1, Ei]  # 设置alpha_i的误差缓存为有效\n",
    "    validEcacheList = nonzero(oS.eCache[:, 0].A)[0]  # 获取所有有效的误差缓存的索引列表\n",
    "    if len(validEcacheList) > 1:  # 如果有多个有效的误差缓存值\n",
    "        for k in validEcacheList:  # 遍历有效的误差缓存值，找到使得delta E最大的alpha_j\n",
    "            if k == i:\n",
    "                continue  # 不计算alpha_i对应的误差，浪费时间\n",
    "            Ek = calcEk(oS, k)  # 计算alpha_k的预测误差\n",
    "            deltaE = abs(Ei - Ek)  # 计算预测误差之差的绝对值\n",
    "            if deltaE > maxDeltaE:  # 找到使得delta E最大的alpha_j\n",
    "                maxK = k\n",
    "                maxDeltaE = deltaE\n",
    "                Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:  # 如果是第一次循环，没有有效的误差缓存值\n",
    "        j = selectJrand(i, oS.m)  # 随机选择一个不等于i的索引值作为alpha_j的索引\n",
    "        Ej = calcEk(oS, j)  # 计算alpha_j的预测误差\n",
    "    return j, Ej\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateEk(oS, k):\n",
    "    \"\"\"\n",
    "    更新误差缓存中样本k的预测误差值\n",
    "    \n",
    "    Args:\n",
    "    oS: optStruct, 优化结构体\n",
    "    k: int, 样本的索引\n",
    "    \"\"\"\n",
    "    Ek = calcEk(oS, k)  # 计算样本k的预测误差\n",
    "    oS.eCache[k] = [1, Ek]  # 更新误差缓存中样本k的预测误差值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerL(i, oS):\n",
    "    \"\"\"\n",
    "    内循环中的优化过程，选择并更新两个变量alpha_i和alpha_j\n",
    "    \n",
    "    Args:\n",
    "    i: int, 第一个变量alpha_i的索引\n",
    "    oS: optStruct, 优化结构体\n",
    "    \n",
    "    Returns:\n",
    "    1: 表示alpha_i和alpha_j已更新\n",
    "    0: 表示alpha_i和alpha_j未更新\n",
    "    \"\"\"\n",
    "    Ei = calcEk(oS, i)  # 计算第一个变量alpha_i的预测误差\n",
    "    if ((oS.labelMat[i] * Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i] * Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        # 检查是否违反KKT条件，需要进行优化\n",
    "        j, Ej = selectJ(i, oS, Ei)  # 选择第二个变量alpha_j\n",
    "        alphaIold = oS.alphas[i].copy()\n",
    "        alphaJold = oS.alphas[j].copy()\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L == H:\n",
    "            print(\"L==H\")\n",
    "            return 0\n",
    "        eta = 2.0 * oS.K[i, j] - oS.K[i, i] - oS.K[j, j]  # 计算eta\n",
    "        if eta >= 0:\n",
    "            print(\"eta>=0\")\n",
    "            return 0\n",
    "        oS.alphas[j] -= oS.labelMat[j] * (Ei - Ej) / eta  # 更新alpha_j\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j], H, L)  # 调整alpha_j的取值范围\n",
    "        updateEk(oS, j)  # 更新alpha_j的误差缓存\n",
    "        if abs(oS.alphas[j] - alphaJold) < 0.00001:\n",
    "            print(\"j not moving enough\")\n",
    "            return 0\n",
    "        oS.alphas[i] += oS.labelMat[j] * oS.labelMat[i] * (alphaJold - oS.alphas[j])  # 更新alpha_i\n",
    "        updateEk(oS, i)  # 更新alpha_i的误差缓存\n",
    "        b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[i, i] - oS.labelMat[j] * (\n",
    "                    oS.alphas[j] - alphaJold) * oS.K[i, j]\n",
    "        b2 = oS.b - Ej - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[i, j] - oS.labelMat[j] * (\n",
    "                    oS.alphas[j] - alphaJold) *oS.K[j, j]\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]):\n",
    "            oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]):\n",
    "            oS.b = b2\n",
    "        else:\n",
    "            oS.b = (b1 + b2) / 2.0\n",
    "            return 1 # 表示alpha_i和alpha_j已更新\n",
    "    else: \n",
    "        return 0 # 表示alpha_i和alpha_j未更新\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoP(dataMatIn, classLabels, C, toler, maxIter, kTup=('lin', 0)):\n",
    "    \"\"\"\n",
    "    Platt SMO算法的外循环函数\n",
    "    \n",
    "    Args:\n",
    "    dataMatIn: array-like, 输入数据矩阵\n",
    "    classLabels: array-like, 类别标签\n",
    "    C: float, 软间隔参数\n",
    "    toler: float, 容错率\n",
    "    maxIter: int, 最大迭代次数\n",
    "    kTup: tuple, 核函数的类型和参数\n",
    "    \n",
    "    Returns:\n",
    "    b: float, 模型的偏置项\n",
    "    alphas: array-like, 模型的拉格朗日乘子\n",
    "    \"\"\"\n",
    "    oS = optStruct(mat(dataMatIn), mat(classLabels).transpose(), C, toler, kTup)  # 初始化优化结构体\n",
    "    iter = 0\n",
    "    entireSet = True\n",
    "    alphaPairsChanged = 0\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "        if entireSet:  # 遍历所有样本\n",
    "            for i in range(oS.m):\n",
    "                alphaPairsChanged += innerL(i, oS)  # 进行优化\n",
    "                print(\"fullSet, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "        else:  # 遍历非边界样本\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i, oS)  # 进行优化\n",
    "                print(\"non-bound, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "        if entireSet:\n",
    "            entireSet = False  # 切换到非边界样本循环\n",
    "        elif (alphaPairsChanged == 0):\n",
    "            entireSet = True  # 切换到全样本循环\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return oS.b, oS.alphas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcWs(alphas, dataArr, classLabels):\n",
    "    \"\"\"\n",
    "    计算模型的回归系数w\n",
    "    \n",
    "    Args:\n",
    "    alphas: array-like, 拉格朗日乘子\n",
    "    dataArr: array-like, 输入数据矩阵\n",
    "    classLabels: array-like, 类别标签\n",
    "    \n",
    "    Returns:\n",
    "    w: array-like, 回归系数\n",
    "    \"\"\"\n",
    "    X = mat(dataArr)\n",
    "    labelMat = mat(classLabels).transpose()\n",
    "    m, n = shape(X)\n",
    "    w = zeros((n, 1))\n",
    "    for i in range(m):\n",
    "        w += multiply(alphas[i] * labelMat[i], X[i, :].T)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testRbf(k1=1.3):\n",
    "    \"\"\"\n",
    "    测试使用RBF核函数的支持向量机模型\n",
    "    \n",
    "    Args:\n",
    "    k1: float, RBF核函数的参数，默认为1.3\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # 加载数据集\n",
    "    dataArr, labelArr = loadDataSet('testSetRBF.txt')\n",
    "    # 调用SMO算法训练模型\n",
    "    b, alphas = smoP(dataArr, labelArr, 200, 0.0001, 10000, ('rbf', k1))\n",
    "    datMat = mat(dataArr)\n",
    "    labelMat = mat(labelArr).transpose()\n",
    "    # 获取支持向量的索引\n",
    "    svInd = nonzero(alphas.A > 0)[0]\n",
    "    sVs = datMat[svInd]  # 仅包含支持向量的数据矩阵\n",
    "    labelSV = labelMat[svInd]  # 支持向量的类别标签\n",
    "    print(\"There are %d Support Vectors\" % shape(sVs)[0])\n",
    "    \n",
    "    m, n = shape(datMat)\n",
    "    errorCount = 0\n",
    "    # 在训练集上进行预测并计算训练误差\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs, datMat[i, :], ('rbf', k1))  # 计算RBF核函数值\n",
    "        predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b  # 根据支持向量、乘子和偏置进行预测\n",
    "        if sign(predict) != sign(labelArr[i]):\n",
    "            errorCount += 1\n",
    "    print(\"The training error rate is: %f\" % (float(errorCount) / m))\n",
    "    \n",
    "    # 加载测试数据集\n",
    "    dataArr, labelArr = loadDataSet('testSetRBF2.txt')\n",
    "    errorCount = 0\n",
    "    datMat = mat(dataArr)\n",
    "    labelMat = mat(labelArr).transpose()\n",
    "    m, n = shape(datMat)\n",
    "    # 在测试集上进行预测并计算测试误差\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs, datMat[i, :], ('rbf', k1))  # 计算RBF核函数值\n",
    "        predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b  # 根据支持向量、乘子和偏置进行预测\n",
    "        if sign(predict) != sign(labelArr[i]):\n",
    "            errorCount += 1\n",
    "    print(\"The test error rate is: %f\" % (float(errorCount) / m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2vector(filename):\n",
    "    \"\"\"\n",
    "    将图像转换为向量表示\n",
    "    \n",
    "    Args:\n",
    "    filename: str, 图像文件名\n",
    "    \n",
    "    Returns:\n",
    "    returnVect: array, 转换后的图像向量，形状为(1, 1024)\n",
    "    \"\"\"\n",
    "    returnVect = zeros((1, 1024))  # 创建一个全零向量，用于存储图像像素值\n",
    "    fr = open(filename)  # 打开图像文件\n",
    "    for i in range(32):  # 读取图像的每一行\n",
    "        lineStr = fr.readline()  # 读取一行图像数据\n",
    "        for j in range(32):  # 遍历每个像素点\n",
    "            returnVect[0, 32 * i + j] = int(lineStr[j])  # 将像素值转换为整数并存储到向量中\n",
    "    return returnVect  # 返回转换后的图像向量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(dirName):\n",
    "    \"\"\"\n",
    "    加载图像数据集\n",
    "    \n",
    "    Args:\n",
    "    dirName: str, 数据集所在的目录名\n",
    "    \n",
    "    Returns:\n",
    "    trainingMat: array, 训练样本矩阵，每一行表示一个图像的向量表示\n",
    "    hwLabels: list, 图像标签列表，每个标签表示对应图像的类别（1或-1）\n",
    "    \"\"\"\n",
    "    from os import listdir\n",
    "    \n",
    "    hwLabels = []  # 存储图像标签的列表\n",
    "    trainingFileList = listdir(dirName)  # 加载训练数据集目录下的文件列表\n",
    "    m = len(trainingFileList)  # 训练样本的数量\n",
    "    trainingMat = zeros((m, 1024))  # 创建一个全零矩阵，用于存储训练样本的向量表示\n",
    "    \n",
    "    for i in range(m):\n",
    "        fileNameStr = trainingFileList[i]  # 获取文件名\n",
    "        fileStr = fileNameStr.split('.')[0]  # 去掉文件名的扩展名\n",
    "        classNumStr = int(fileStr.split('_')[0])  # 提取图像的类别标签\n",
    "        if classNumStr == 9:\n",
    "            hwLabels.append(-1)  # 如果图像类别为9，则标签为-1\n",
    "        else:\n",
    "            hwLabels.append(1)  # 否则标签为1\n",
    "        trainingMat[i, :] = img2vector('%s/%s' % (dirName, fileNameStr))  # 将图像转换为向量表示，并存储到训练样本矩阵中\n",
    "        \n",
    "    return trainingMat, hwLabels  # 返回训练样本矩阵和图像标签列表\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testDigits(kTup=('rbf', 10)):\n",
    "    \"\"\"\n",
    "    测试手写数字识别系统\n",
    "    \n",
    "    Args:\n",
    "    kTup: tuple, 核函数的类型和参数，默认为('rbf', 10)\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    dataArr, labelArr = loadImages('trainingDigits')  # 加载训练数据集\n",
    "    b, alphas = smoP(dataArr, labelArr, 200, 0.0001, 10000, kTup)  # 使用SMO算法训练SVM模型\n",
    "    datMat = mat(dataArr)\n",
    "    labelMat = mat(labelArr).transpose()\n",
    "    svInd = nonzero(alphas.A > 0)[0]  # 获取支持向量的索引\n",
    "    sVs = datMat[svInd]  # 获取支持向量对应的训练样本\n",
    "    labelSV = labelMat[svInd]  # 获取支持向量对应的标签\n",
    "    print(\"There are %d Support Vectors\" % shape(sVs)[0])\n",
    "    m, n = shape(datMat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs, datMat[i, :], kTup)  # 计算训练样本与支持向量之间的核函数值\n",
    "        predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b  # 使用核函数进行预测\n",
    "        if sign(predict) != sign(labelArr[i]):\n",
    "            errorCount += 1\n",
    "    print(\"The training error rate is: %f\" % (float(errorCount) / m))\n",
    "    \n",
    "    dataArr, labelArr = loadImages('testDigits')  # 加载测试数据集\n",
    "    errorCount = 0\n",
    "    datMat = mat(dataArr)\n",
    "    labelMat = mat(labelArr).transpose()\n",
    "    m, n = shape(datMat)\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs, datMat[i, :], kTup)  # 计算测试样本与支持向量之间的核函数值\n",
    "        predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b  # 使用核函数进行预测\n",
    "        if sign(predict) != sign(labelArr[i]):\n",
    "            errorCount += 1\n",
    "    print(\"The test error rate is: %f\" % (float(errorCount) / m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optStructK:\n",
    "    def __init__(self, dataMatIn, classLabels, C, toler):\n",
    "        \"\"\"\n",
    "        初始化非核版本的优化结构体\n",
    "\n",
    "        Args:\n",
    "        dataMatIn: array-like, 特征数据集\n",
    "        classLabels: array-like, 类别标签\n",
    "        C: float, 软间隔参数\n",
    "        toler: float, 容错率\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.X = dataMatIn  # 特征数据集\n",
    "        self.labelMat = classLabels  # 类别标签\n",
    "        self.C = C  # 软间隔参数\n",
    "        self.tol = toler  # 容错率\n",
    "        self.m = shape(dataMatIn)[0]  # 数据集的样本数\n",
    "        self.alphas = mat(zeros((self.m, 1)))  # 存储拉格朗日乘子\n",
    "        self.b = 0  # 分类器的偏置项\n",
    "        self.eCache = mat(zeros((self.m, 2)))  # 误差缓存，第一列为有效标志位\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEkK(oS, k):\n",
    "    \"\"\"\n",
    "    计算第k个样本的预测误差\n",
    "\n",
    "    Args:\n",
    "    oS: optStructK对象，优化结构体\n",
    "    k: int，样本索引\n",
    "\n",
    "    Returns:\n",
    "    Ek: float，预测误差\n",
    "    \"\"\"\n",
    "    fXk = float(multiply(oS.alphas, oS.labelMat).T * (oS.X * oS.X[k, :].T)) + oS.b  # 计算f(x_k)\n",
    "    Ek = fXk - float(oS.labelMat[k])  # 计算预测误差Ek\n",
    "    return Ek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectJK(i, oS, Ei):\n",
    "    \"\"\"\n",
    "    选择第二个变量和计算对应的预测误差Ej\n",
    "\n",
    "    Args:\n",
    "    i: int，第一个变量的索引\n",
    "    oS: optStruct对象，优化结构体\n",
    "    Ei: float，第一个变量的预测误差\n",
    "\n",
    "    Returns:\n",
    "    maxK: int，选择的第二个变量的索引\n",
    "    Ej: float，第二个变量的预测误差\n",
    "    \"\"\"\n",
    "    maxK = -1  # 保存选择的第二个变量的索引\n",
    "    maxDeltaE = 0  # 保存最大的预测误差变化值\n",
    "    Ej = 0  # 保存第二个变量的预测误差\n",
    "    oS.eCache[i] = [1, Ei]  # 设置第一个变量的缓存为有效值\n",
    "\n",
    "    # 获取缓存中有效的E值的索引列表\n",
    "    validEcacheList = nonzero(oS.eCache[:, 0].A)[0]\n",
    "\n",
    "    if len(validEcacheList) > 1:\n",
    "        # 遍历有效的E值列表，选择使得预测误差变化值最大的第二个变量\n",
    "        for k in validEcacheList:\n",
    "            if k == i:\n",
    "                continue  # 不计算第一个变量的预测误差\n",
    "            Ek = calcEk(oS, k)  # 计算第二个变量的预测误差\n",
    "            deltaE = abs(Ei - Ek)  # 计算预测误差的变化值\n",
    "            if deltaE > maxDeltaE:\n",
    "                maxK = k\n",
    "                maxDeltaE = deltaE\n",
    "                Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:\n",
    "        # 如果缓存中没有有效的E值（第一次迭代），则随机选择第二个变量\n",
    "        j = selectJrand(i, oS.m)\n",
    "        Ej = calcEk(oS, j)\n",
    "    return j, Ej\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateEkK(oS, k):\n",
    "    \"\"\"\n",
    "    更新缓存中第k个样本的预测误差Ek\n",
    "\n",
    "    Args:\n",
    "    oS: optStruct对象，优化结构体\n",
    "    k: int，样本索引\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    Ek = calcEk(oS, k)  # 计算第k个样本的预测误差\n",
    "    oS.eCache[k] = [1, Ek]  # 更新缓存中第k个样本的预测误差\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerLK(i, oS):\n",
    "    \"\"\"\n",
    "    SMO算法的内层循环函数，用于选择第二个变量和执行优化更新\n",
    "\n",
    "    Args:\n",
    "    i: int，第一个变量的索引\n",
    "    oS: optStruct对象，优化结构体\n",
    "\n",
    "    Returns:\n",
    "    int，返回1表示成功更新了一对alpha值，返回0表示未能更新\n",
    "    \"\"\"\n",
    "    Ei = calcEk(oS, i)  # 计算第一个变量的预测误差Ei\n",
    "    if ((oS.labelMat[i] * Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i] * Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        # 检查第一个变量是否违反KKT条件，如果违反则选择第二个变量并执行优化更新\n",
    "        j, Ej = selectJ(i, oS, Ei)  # 选择第二个变量和计算预测误差Ej\n",
    "        alphaIold = oS.alphas[i].copy()  # 备份旧的alpha_i\n",
    "        alphaJold = oS.alphas[j].copy()  # 备份旧的alpha_j\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])  # 计算alpha_j的取值范围下界L\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])  # 计算alpha_j的取值范围上界H\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)  # 计算alpha_j的取值范围下界L\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])  # 计算alpha_j的取值范围上界H\n",
    "        if L == H:\n",
    "            print(\"L==H\")\n",
    "            return 0  # 如果取值范围下界和上界相等，无法进行优化更新，返回0表示未能更新\n",
    "\n",
    "        eta = 2.0 * oS.X[i, :] * oS.X[j, :].T - oS.X[i, :] * oS.X[i, :].T - oS.X[j, :] * oS.X[j, :].T  # 计算eta\n",
    "        if eta >= 0:\n",
    "            print(\"eta>=0\")\n",
    "            return 0  # 如果eta大于等于0，无法进行优化更新，返回0表示未能更新\n",
    "\n",
    "        oS.alphas[j] -= oS.labelMat[j] * (Ei - Ej) / eta  # 更新alpha_j\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j], H, L)  # 对alpha_j进行修剪\n",
    "        updateEk(oS, j)  # 更新第二个变量的预测误差\n",
    "\n",
    "        if abs(oS.alphas[j] - alphaJold) < 0.00001: \n",
    "            print(\"j not moving enough\")\n",
    "            return 0 # 如果alpha_j的变化量很小，表示未能更新，返回0\n",
    "            oS.alphas[i] += oS.labelMat[j] * oS.labelMat[i] * (alphaJold - oS.alphas[j])  # 更新alpha_i\n",
    "        updateEk(oS, i)  # 更新第一个变量的预测误差\n",
    "\n",
    "        b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.X[i, :] * oS.X[i, :].T - oS.labelMat[j] * (\n",
    "                oS.alphas[j] - alphaJold) * oS.X[i, :] * oS.X[j, :].T  # 更新b1\n",
    "        b2 = oS.b - Ej - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.X[i, :] * oS.X[j, :].T - oS.labelMat[j] * (\n",
    "                oS.alphas[j] - alphaJold) * oS.X[j, :] * oS.X[j, :].T  # 更新b2\n",
    "\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]):\n",
    "            oS.b = b1  # 如果alpha_i在取值范围内，更新b为b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]):\n",
    "            oS.b = b2  # 如果alpha_j在取值范围内，更新b为b2\n",
    "        else:\n",
    "            oS.b = (b1 + b2) / 2.0  # 否则更新b为b1和b2的平均值\n",
    "\n",
    "        return 1  # 成功更新了一对alpha值，返回1\n",
    "    else:\n",
    "        return 0  # 未能更新，返回0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义SMO算法函数，输入参数包括数据矩阵、类别标签、惩罚系数C、容错率tolerance和最大迭代次数maxIter\n",
    "def smoPK(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    # 创建optStruct对象oS，该对象保存所有重要的值\n",
    "    oS = optStruct(mat(dataMatIn),mat(classLabels).transpose(),C,toler)\n",
    "    iter = 0 # 初始化迭代次数iter为0\n",
    "    entireSet = True # 初始化entireSet变量为True，表示默认遍历整个数据集\n",
    "    alphaPairsChanged = 0 # 记录alpha是否已经进行了优化\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        # 初始化alphaPairsChanged，在每次循环时设为0，用于记录alpha是否已经进行了优化\n",
    "        alphaPairsChanged = 0\n",
    "        # 如果entireSet为True或者alphaPairsChanged不等于0，则遍历整个数据集\n",
    "        if entireSet:\n",
    "            for i in range(oS.m): # 遍历所有样本点\n",
    "                alphaPairsChanged += innerL(i,oS) # 使用innerL选择第二个alpha，并在可能时对其进行优化处理\n",
    "                print(\"fullSet, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged))\n",
    "            iter += 1 # 更新迭代次数\n",
    "        else: # 遍历非边界alpha值，也就是那些不等于0和C的值\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0] # 遍历所有非边界alpha值\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i,oS) # 使用innerL选择第二个alpha，并在可能时对其进行优化处理\n",
    "                print(\"non-bound, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged))\n",
    "            iter += 1 # 更新迭代次数\n",
    "        if entireSet: entireSet = False # 如果本次遍历了整个数据集，则下次将遍历非边界值\n",
    "        elif (alphaPairsChanged == 0): entireSet = True  # 如果有一次alpha未更新，则遍历整个数据集\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return oS.b,oS.alphas # 返回训练完毕后的b和alphas\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
